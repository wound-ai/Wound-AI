{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnCRkf0Sjx1H78jgtBsvBA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wound-ai/Wound-AI/blob/main/ensemble-inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P7iQvh6RXs-k"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "class Ensemble:\n",
        "  def __init__(self, dls, models : dict, vocab : list=[0, 1]):\n",
        "    self.models = models\n",
        "    self.vocab = vocab\n",
        "    self.dls = dls\n",
        "    self.model_list = models.values()\n",
        "    print(f'vocab: {self.vocab}')\n",
        "    for name, model in models.items():\n",
        "      print(f'loaded: {name}')\n",
        "\n",
        "\n",
        "  def calc_probas(self, item):\n",
        "    probas = []\n",
        "    for _, model in self.models.items():\n",
        "      _, _, p = model.predict(item)\n",
        "      probas.append(p)\n",
        "\n",
        "    probas = torch.stack(probas, dim=0)\n",
        "    return probas\n",
        "\n",
        "  def predict(self, item):\n",
        "    probas = self.calc_probas(item)\n",
        "    mean, std = probas.mean(axis=0), probas.std(axis=0)\n",
        "\n",
        "    return self.vocab[mean.argmax()], mean.argmax(), std\n",
        "\n",
        "  def get_preds(self, ds_idx=1, dl=None, with_input=False, with_decoded=False, with_loss=False, act=None, inner=False, reorder=True, cbs=None, **kwargs):\n",
        "\n",
        "    if dl is None: dl = self.dls[1]\n",
        "\n",
        "    predictions = []\n",
        "    losses = []\n",
        "    res = []\n",
        "\n",
        "    for name, model in self.models.items():\n",
        "      print(f'Getting predictions from {name} \\n')\n",
        "      inputs, preds, targs, decoded, loss = model.get_preds(dl=dls.valid, with_input=True, with_loss=True, with_decoded=True)\n",
        "      predictions.append(preds)\n",
        "      losses.append(loss)\n",
        "\n",
        "    preds = torch.stack(predictions).mean(0)\n",
        "    decoded = preds.argmax(1)\n",
        "\n",
        "    if with_input:\n",
        "      res.append(inputs)\n",
        "\n",
        "    res.append(preds)\n",
        "    res.append(targs)\n",
        "\n",
        "    if with_decoded:\n",
        "      res.append(decoded)\n",
        "\n",
        "    if with_loss:\n",
        "      res.append(torch.stack(losses, dim=1).mean(1))\n",
        "\n",
        "    return tuple(res)\n",
        "\n",
        "  def calc_metrics(self, metrics : dict):\n",
        "    res = {}\n",
        "    predictions, targs, decoded, losses = self.get_preds(dl=self.dls.valid, with_input=False, with_loss=True, with_decoded=True)\n",
        "    for name, metric in metrics.items():\n",
        "      res[name] = metric(decoded, targs)\n",
        "    return res\n",
        "\n",
        "  def export(self, fname):\n",
        "    \"\"\"\n",
        "    Saves the Ensemble object to a file using pickle.\n",
        "    \"\"\"\n",
        "    with open(fname, 'wb') as f:\n",
        "      pickle.dump(self, f) # Save the entire Ensemble object"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eqsb4LaCXtdc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}